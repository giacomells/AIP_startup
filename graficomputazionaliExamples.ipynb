{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with three layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tgraph [size=\"12,12\"]\n",
      "\tnode [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]\n",
      "\t140253905779664 [label=\"\n",
      " (1, 10)\" fillcolor=darkolivegreen1]\n",
      "\t140253905984672 [label=SoftmaxBackward0]\n",
      "\t140253905984288 -> 140253905984672\n",
      "\t140253905984288 [label=AddmmBackward0]\n",
      "\t140253905982944 -> 140253905984288\n",
      "\t140253905779504 [label=\"fc3.bias\n",
      " (10)\" fillcolor=lightblue]\n",
      "\t140253905779504 -> 140253905982944\n",
      "\t140253905982944 [label=AccumulateGrad]\n",
      "\t140253905982560 -> 140253905984288\n",
      "\t140253905982560 [label=ReluBackward0]\n",
      "\t140253905984960 -> 140253905982560\n",
      "\t140253905984960 [label=AddmmBackward0]\n",
      "\t140253905981552 -> 140253905984960\n",
      "\t140253830777248 [label=\"fc2.bias\n",
      " (64)\" fillcolor=lightblue]\n",
      "\t140253830777248 -> 140253905981552\n",
      "\t140253905981552 [label=AccumulateGrad]\n",
      "\t140253905985296 -> 140253905984960\n",
      "\t140253905985296 [label=ReluBackward0]\n",
      "\t140253905982368 -> 140253905985296\n",
      "\t140253905982368 [label=AddmmBackward0]\n",
      "\t140253905982752 -> 140253905982368\n",
      "\t140253905779184 [label=\"fc1.bias\n",
      " (128)\" fillcolor=lightblue]\n",
      "\t140253905779184 -> 140253905982752\n",
      "\t140253905982752 [label=AccumulateGrad]\n",
      "\t140253905984240 -> 140253905982368\n",
      "\t140253905984240 [label=TBackward0]\n",
      "\t140253905984048 -> 140253905984240\n",
      "\t140253903137664 [label=\"fc1.weight\n",
      " (128, 784)\" fillcolor=lightblue]\n",
      "\t140253903137664 -> 140253905984048\n",
      "\t140253905984048 [label=AccumulateGrad]\n",
      "\t140253905985200 -> 140253905984960\n",
      "\t140253905985200 [label=TBackward0]\n",
      "\t140253905984000 -> 140253905985200\n",
      "\t140253906652192 [label=\"fc2.weight\n",
      " (64, 128)\" fillcolor=lightblue]\n",
      "\t140253906652192 -> 140253905984000\n",
      "\t140253905984000 [label=AccumulateGrad]\n",
      "\t140253905981984 -> 140253905984288\n",
      "\t140253905981984 [label=TBackward0]\n",
      "\t140253905982032 -> 140253905981984\n",
      "\t140253905779104 [label=\"fc3.weight\n",
      " (10, 64)\" fillcolor=lightblue]\n",
      "\t140253905779104 -> 140253905982032\n",
      "\t140253905982032 [label=AccumulateGrad]\n",
      "\t140253905984672 -> 140253905779664\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computation_graph.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Definizione del modello\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Dati dummy\n",
    "x_dummy = torch.randn(1, 784)\n",
    "\n",
    "# Generazione del grafocomputazionale\n",
    "y = model(x_dummy)\n",
    "graph = make_dot(y, params=dict(model.named_parameters()))\n",
    "print(graph.source)\n",
    "graph.render(\"computation_graph\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight does not have gradient\n",
      "fc1.bias does not have gradient\n",
      "fc2.weight does not have gradient\n",
      "fc2.bias does not have gradient\n",
      "fc3.weight does not have gradient\n",
      "fc3.bias does not have gradient\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name} has gradient\")\n",
    "    else:\n",
    "        print(f\"{name} does not have gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tgraph [size=\"12,12\"]\n",
      "\tnode [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]\n",
      "\t140253905908016 [label=\"\n",
      " (1, 64)\" fillcolor=darkolivegreen1]\n",
      "\t140253906032144 [label=SoftmaxBackward0]\n",
      "\t140253906031472 -> 140253906032144\n",
      "\t140253906031472 [label=AddmmBackward0]\n",
      "\t140253906033968 -> 140253906031472\n",
      "\t140253906368208 [label=\"fc2.bias\n",
      " (64)\" fillcolor=lightblue]\n",
      "\t140253906368208 -> 140253906033968\n",
      "\t140253906033968 [label=AccumulateGrad]\n",
      "\t140253906034400 -> 140253906031472\n",
      "\t140253906034400 [label=ReluBackward0]\n",
      "\t140253906034496 -> 140253906034400\n",
      "\t140253906034496 [label=AddmmBackward0]\n",
      "\t140253906030800 -> 140253906034496\n",
      "\t140253903489920 [label=\"fc1.bias\n",
      " (128)\" fillcolor=lightblue]\n",
      "\t140253903489920 -> 140253906030800\n",
      "\t140253906030800 [label=AccumulateGrad]\n",
      "\t140253906032096 -> 140253906034496\n",
      "\t140253906032096 [label=TBackward0]\n",
      "\t140253906034448 -> 140253906032096\n",
      "\t140253905779424 [label=\"fc1.weight\n",
      " (128, 784)\" fillcolor=lightblue]\n",
      "\t140253905779424 -> 140253906034448\n",
      "\t140253906034448 [label=AccumulateGrad]\n",
      "\t140253906031808 -> 140253906031472\n",
      "\t140253906031808 [label=TBackward0]\n",
      "\t140253906031232 -> 140253906031808\n",
      "\t140253905516160 [label=\"fc2.weight\n",
      " (64, 128)\" fillcolor=lightblue]\n",
      "\t140253905516160 -> 140253906031232\n",
      "\t140253906031232 [label=AccumulateGrad]\n",
      "\t140253906032144 -> 140253905908016\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computation_graph_two_layers.png'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Definizione del modello\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Dati dummy\n",
    "x_dummy = torch.randn(1, 784)\n",
    "\n",
    "# Generazione del grafocomputazionale\n",
    "y = model(x_dummy)\n",
    "graph = make_dot(y, params=dict(model.named_parameters()))\n",
    "print(graph.source)\n",
    "graph.render(\"computation_graph_two_layers\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tgraph [size=\"12,12\"]\n",
      "\tnode [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]\n",
      "\t140253905998768 [label=\"\n",
      " (1, 64)\" fillcolor=darkolivegreen1]\n",
      "\t140253906656224 [label=SoftmaxBackward0]\n",
      "\t140253906654688 -> 140253906656224\n",
      "\t140253906654688 [label=AddmmBackward0]\n",
      "\t140253906033968 -> 140253906654688\n",
      "\t140253906368208 [label=\"fc2.bias\n",
      " (64)\" fillcolor=lightblue]\n",
      "\t140253906368208 -> 140253906033968\n",
      "\t140253906033968 [label=AccumulateGrad]\n",
      "\t140253906655744 -> 140253906654688\n",
      "\t140253906655744 [label=ReluBackward0]\n",
      "\t140253811753792 -> 140253906655744\n",
      "\t140253811753792 [label=AddmmBackward0]\n",
      "\t140253906030800 -> 140253811753792\n",
      "\t140253903489920 [label=\"fc1.bias\n",
      " (128)\" fillcolor=lightblue]\n",
      "\t140253903489920 -> 140253906030800\n",
      "\t140253906030800 [label=AccumulateGrad]\n",
      "\t140253906033008 -> 140253811753792\n",
      "\t140253906033008 [label=TBackward0]\n",
      "\t140253906034448 -> 140253906033008\n",
      "\t140253905779424 [label=\"fc1.weight\n",
      " (128, 784)\" fillcolor=lightblue]\n",
      "\t140253905779424 -> 140253906034448\n",
      "\t140253906034448 [label=AccumulateGrad]\n",
      "\t140253906655456 -> 140253906654688\n",
      "\t140253906655456 [label=TBackward0]\n",
      "\t140253906031232 -> 140253906655456\n",
      "\t140253905516160 [label=\"fc2.weight\n",
      " (64, 128)\" fillcolor=lightblue]\n",
      "\t140253905516160 -> 140253906031232\n",
      "\t140253906031232 [label=AccumulateGrad]\n",
      "\t140253906656224 -> 140253905998768\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computation_graph_two_layers.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with torch.no_grad():\n",
    "    #for name, param in model.named_parameters():\n",
    "model.eval() \n",
    "\n",
    "# Dati dummy\n",
    "x_dummy = torch.randn(1, 784)\n",
    "\n",
    "# Generazione del grafocomputazionale\n",
    "y = model(x_dummy)\n",
    "graph = make_dot(y, params=dict(model.named_parameters()))\n",
    "print(graph.source)\n",
    "graph.render(\"computation_graph_two_layers\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Mathematical Operations ===\n",
      "\n",
      "Layer: fc1 (Linear)\n",
      "Operation: output = input @ weight.T + bias\n",
      "Parameters: {'in_features': 784, 'out_features': 128}\n",
      "Output shape: torch.Size([1, 128])\n",
      "Stats: mean=-0.0059, std=0.5833\n",
      "\n",
      "Layer: fc2 (Linear)\n",
      "Operation: output = input @ weight.T + bias\n",
      "Parameters: {'in_features': 128, 'out_features': 64}\n",
      "Output shape: torch.Size([1, 64])\n",
      "Stats: mean=-0.0123, std=0.2605\n",
      "\n",
      "Analysis completed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.operations = {}\n",
    "        self.layer_stats = {}\n",
    "        self.hooks = []\n",
    "    \n",
    "    def analyze(self, input_tensor):\n",
    "        # Register hooks to analyze operations\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.Module) and not isinstance(module, nn.Sequential):\n",
    "                if list(module.children()) and module == self.model:\n",
    "                    continue\n",
    "                self.hooks.append(module.register_forward_hook(self._hook_fn))\n",
    "        \n",
    "        # Perform forward pass\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n=== Model Mathematical Operations ===\")\n",
    "        for name, op in self.operations.items():\n",
    "            print(f\"\\nLayer: {name} ({op['type']})\")\n",
    "            print(f\"Operation: {op['operation']}\")\n",
    "            if op['parameters']:\n",
    "                print(f\"Parameters: {op['parameters']}\")\n",
    "            if name in self.layer_stats:\n",
    "                stats = self.layer_stats[name]\n",
    "                print(f\"Output shape: {stats['shape']}\")\n",
    "                print(f\"Stats: mean={stats['mean']:.4f}, std={stats['std']:.4f}\")\n",
    "        \n",
    "        return self.operations, self.layer_stats\n",
    "    \n",
    "    def _hook_fn(self, module, input, output):\n",
    "        # Identify module name\n",
    "        module_name = None\n",
    "        for name, mod in self.model.named_modules():\n",
    "            if mod is module:\n",
    "                module_name = name\n",
    "                break\n",
    "        if not module_name:\n",
    "            module_name = str(module)\n",
    "        \n",
    "        # Save statistics\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            self.layer_stats[module_name] = {\n",
    "                'shape': output.shape,\n",
    "                'mean': output.mean().item(),\n",
    "                'std': output.std().item(),\n",
    "                'min': output.min().item(),\n",
    "                'max': output.max().item()\n",
    "            }\n",
    "        \n",
    "        # Identify operation\n",
    "        op_info = {'type': module.__class__.__name__, 'parameters': {}, 'operation': ''}\n",
    "        \n",
    "        # Analyze layer type\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            op_info['parameters'] = {\n",
    "                'in_channels': module.in_channels,\n",
    "                'out_channels': module.out_channels,\n",
    "                'kernel_size': module.kernel_size\n",
    "            }\n",
    "            op_info['operation'] = \"output = conv2D(input, weight) + bias\"\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            op_info['parameters'] = {\n",
    "                'in_features': module.in_features,\n",
    "                'out_features': module.out_features\n",
    "            }\n",
    "            op_info['operation'] = \"output = input @ weight.T + bias\"\n",
    "        elif isinstance(module, nn.ReLU):\n",
    "            op_info['operation'] = \"output = max(0, input)\"\n",
    "        elif isinstance(module, nn.MaxPool2d):\n",
    "            op_info['parameters'] = {'kernel_size': module.kernel_size}\n",
    "            op_info['operation'] = \"output = max_value(input, kernel_size)\"\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            op_info['operation'] = \"output = (input - mean) / sqrt(var + eps) * weight + bias\"\n",
    "        else:\n",
    "            op_info['operation'] = \"Custom operation\"\n",
    "        \n",
    "        self.operations[module_name] = op_info\n",
    "\n",
    "# Main function to analyze a model\n",
    "def analyze_model(model, input_tensor):\n",
    "    # Analyze the model\n",
    "    analyzer = ModelAnalyzer(model)\n",
    "    operations, stats = analyzer.analyze(input_tensor)\n",
    "    \n",
    "    return operations, stats\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the provided model and x_dummy tensor\n",
    "    operations, stats = analyze_model(model, x_dummy)\n",
    "    \n",
    "    print(\"\\nAnalysis completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
